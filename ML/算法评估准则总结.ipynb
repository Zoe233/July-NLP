{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法评估准则总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href='#cross_validation'>交叉验证原理小结</a>\n",
    "- <a href='#precision_recall'>精确率与召回率，RoC曲线与PR曲线</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='cross_validation'>交叉验证原理小结</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 什么是交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉验证是在机器学习建立模型和验证模型参数时常用的办法。\n",
    "\n",
    "交叉验证，顾名思义，就是**重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏**。\n",
    "\n",
    "在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 交叉验证的使用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么什么时候才需要交叉验证呢？\n",
    "\n",
    "交叉验证用在**数据不是很充足**的时候。\n",
    "\n",
    "比如：   \n",
    "在我日常项目里面，对于普通适中问题，如果数据**样本量小于一万条**，我们就会采用交叉验证来训练优化选择模型。   \n",
    "如果**样本大于一万条**的话，我们一般随机的把数据分成三份，一份为训练集（Training Set），一份为验证集（Validation Set），最后一份为测试集（Test Set）。\n",
    "- 用训练集来训练模型，\n",
    "- 用验证集来评估模型预测的好坏和选择模型及其对应的参数。\n",
    "- 把最终得到的模型再用于测试集，最终决定使用哪个模型以及对应参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 交叉验证的不同方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回到交叉验证，根据切分的方法不同，交叉验证分为下面三种：\n",
    "- 简单交叉验证\n",
    "- S折交叉验证\n",
    "- 留一交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 第一种是**简单交叉验证**。\n",
    "\n",
    "所谓的简单，是和其他交叉验证方法相对而言的。\n",
    "\n",
    "首先，我们随机的将样本数据分为**两部分（比如： 70%的训练集，30%的测试集）**，然后用训练集来训练模型，在测试集上验证模型及参数。\n",
    "\n",
    "接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。\n",
    "\n",
    "最后我们选择损失函数评估最优的模型和参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 第二种是**S折交叉验证（S-Folder Cross Validation）**。\n",
    "\n",
    "和第一种方法不同，S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。\n",
    "\n",
    "当这一轮完成后，重新随机选择S-1份来训练数据。\n",
    "\n",
    "若干轮（小于S）之后，选择损失函数评估最优的模型和参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 第三种是留一交叉验证（Leave-one-out Cross Validation）。   \n",
    "\n",
    "它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。\n",
    "\n",
    "此方法主要用于**样本量非常少的情况**，比如对于普通适中问题，**N小于50时，我一般采用留一交叉验证。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 如何选择不同的交叉验证方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过反复的交叉验证，用损失函数来度量得到的模型的好坏，最终我们可以得到一个较好的模型。\n",
    "\n",
    "那这三种情况，到底我们应该**选择哪一种方法呢？**\n",
    "\n",
    "一句话总结，如果我们只是对数据做一个初步的模型建立，不是要做深入分析的话，简单交叉验证就可以了。\n",
    "\n",
    "否则就用S折交叉验证。\n",
    "\n",
    "在样本量少的时候，使用S折交叉验证的特例留一交叉验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外还有一种比较特殊的交叉验证方式，也是用于**样本量少**的时候。叫做**自助法(bootstrapping)**。\n",
    "\n",
    "比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。   \n",
    "这样重复采集m次，我们得到m个样本组成的训练集。   \n",
    "当然，这m个样本中很有可能有重复的样本数据。   \n",
    "同时，用**没有被采样到的样本做测试集。**     \n",
    "\n",
    "这样接着进行交叉验证。由于我们的训练集有重复数据，这会**改变数据的分布**，因而训练结果会有**估计偏差**，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='precision_recall'>精确率与召回率，RoC曲线与PR曲线</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习的算法评估中，尤其是分类算法评估中，我们经常听到精确率(precision)与召回率(recall)，RoC曲线与PR曲线这些概念，那这些概念到底有什么用处呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们需要搞清楚几个拗口的概念："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True Positives,TP：预测为正样本，实际也为正样本的特征数\n",
    "- False Positives,FP：预测为正样本，实际为负样本的特征数\n",
    "\n",
    "\n",
    "- True Negatives,TN：预测为负样本，实际也为负样本的特征数\n",
    "- False Negatives,FN：预测为负样本，实际为正样本的特征数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "听起来还是很费劲，不过我们用一张图就很容易理解了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图如下所示，里面：\n",
    "- 绿色的半圆就是TP(True Positives), \n",
    "- 红色的半圆就是FP(False Positives), \n",
    "- 左边的灰色长方形（不包括绿色半圆），就是FN（False Negatives）。\n",
    "- 右边的 浅灰色长方形（不包括红色半圆），就是TN(True Negatives)。\n",
    "\n",
    "这个绿色和红色组成的**圆内**代表我们分类得到模型结果认为是**正值**的样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/tpfptnfn.jpg' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 精确率Precision，召回率Recall 与 特异性Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精确率（Precision）的定义在上图可以看出，是绿色半圆除以红色绿色组成的圆。\n",
    "\n",
    "严格的数学定义如下：\n",
    "$$P=\\frac{TP}{TP+FP}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "召回率(Recall)的定义也在图上能看出，是绿色半圆除以左边的长方形。严格的数学定义如下：\n",
    "$$R=\\frac{TP}{TP+FN}$$  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特异性(specificity)的定义图上没有直接写明，这里给出，是右边长方形去掉红色半圆部分后除以右边的长方形。\n",
    "\n",
    "严格的数学定义如下：\n",
    "\n",
    "$$S=\\frac{TN}{FP+TN}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时也用一个**F1值**来**综合评估精确率和召回率**，它是**精确率和召回率的调和均值**。\n",
    "\n",
    "当精确率和召回率都高时，F1值也会高。\n",
    "\n",
    "严格的数学定义如下：\n",
    "$$\\frac{2}{F_1}=\\frac{1}{P}+\\frac{1}{R}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候我们对精确率和召回率并不是一视同仁，比如有时候我们更加重视精确率。\n",
    "\n",
    "我们用一个**参数β**来度量两者之间的关系。\n",
    "\n",
    "- 如果β>1, 召回率有更大影响，\n",
    "- 如果β<1,精确率有更大影响。\n",
    "- 自然，当β=1的时候，精确率和召回率影响力相同，和F1形式一样。\n",
    "\n",
    "含有度量参数β的F1我们记为Fβ, 严格的数学定义如下：\n",
    "\n",
    "$$F_β=\\frac{(1+β^2)∗P∗R}{β^2∗P+R}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外还有**灵敏度(true positive rate ,TPR)**，它是所有实际正例中，正确识别的正例比例，它和召回率的表达式没有区别。\n",
    "\n",
    "严格的数学定义如下：\n",
    "$$TPR=\\frac{TP}{TP+FN}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一个是**1-特异度(false positive rate, FPR)**，它是实际负例中，错误得识别为正例的负例比例。\n",
    "\n",
    "严格的数学定义如下：\n",
    "$$FPR=\\frac{FP}{FP+TN}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们熟悉了精确率， 召回率和特异性，以及TPR和FPR，后面的RoC曲线和PR曲线就好了解了。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RoC曲线和PR曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上面精确率， 召回率和特异性的基础，理解RoC曲线和PR曲线就小菜一碟了。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**以TPR为y轴，以FPR为x轴，我们就直接得到了RoC曲线。**\n",
    "\n",
    "从FPR和TPR的定义可以理解，**TPR越高，FPR越小**，我们的模型和算法就越高效。\n",
    "\n",
    "也就是画出来的RoC曲线越靠近左上越好。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下图左图所示。  \n",
    "从几何的角度讲，RoC曲线下方的面积越大越大，则模型越优。  \n",
    "所以有时候我们用RoC曲线下的面积，即**AUC（Area Under Curve）值**来作为算法和模型好坏的标准。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/roc.png' width='90%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**以精确率为y轴，以召回率为x轴，我们就得到了PR曲线。**   \n",
    "仍然从精确率和召回率的定义可以理解，精确率越高，召回率越高，我们的模型和算法就越高效。也就是画出来的PR曲线越靠近**右上越好**。如上图右图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用RoC曲线和PR曲线，我们就能很方便的评估我们的模型的分类能力的优劣了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有参考网址：https://www.cnblogs.com/dlml/p/4403482.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
