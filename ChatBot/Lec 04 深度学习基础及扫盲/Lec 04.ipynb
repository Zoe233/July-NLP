{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec 04 深度学习基础及扫盲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要内容：\n",
    "- <a href='#rnn'>1. 循环神经网络RNN</a>\n",
    "    - <a href='#rnn1'>1.1 场景与多种引用</a>\n",
    "    - <a href='#rnn2'>1.2 NLP文字序列最爱的RNN</a>\n",
    "    - <a href='#rnn3'>1.3 BPTT算法</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href='#lstm'>2. LSTM</a>\n",
    "    - <a href='#lstm1'>2.1 长时依赖问题</a>\n",
    "    - <a href='#lstm2'>2.2 “记忆细胞”与状态</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href='#application'>3.NLP的应用</a>\n",
    "    - <a href='#application1'>3.1 各式各样的生成模型</a>\n",
    "    - <a href='#application2'>3.2 看图说话基础版与高级版</a>\n",
    "    - <a href='#application3'>3.3 序列到序列学习（机器翻译等）</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a name='rnn'>1. 循环神经网络RNN</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a name='rnn1'>1.1 场景与多种引用</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在自然语言处理中，另外一个重要的应用领域，就是**文本的自动撰写**。\n",
    "\n",
    "关键词、关键短语、自动摘要提取都属于这个领域中的一种应用。\n",
    "不过这些应用，都是由多到少的生成。\n",
    "\n",
    "这里我们介绍其另外一种应用：由少到多的生成，包括句子的复写，由关键词、主题生成文章或者段落等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/rnn1.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/rnn2.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/rnn3.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/rnn4.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "序列到序列，Seq2Seq的应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/rnn5.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络到循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/nn1.png' width='70%'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在神经网络中，我们有很多种的结构和名称。\n",
    "\n",
    "如：\n",
    "- MLP/DNN： 一般的神经网络结构比较简单，input layer, n * hidden layer , output layer\n",
    "- CNN卷积神经网络，主要用于处理图像，也可以应用于自然语言处理等多方面\n",
    "- RNN( LSTM, GRU)： "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 循环神经网络RNN\n",
    "\n",
    "为什么有BP神经网络，CNN，还要RNN?\n",
    "- 传统神经网络（包括CNN），输入和输出都是相互独立的。\n",
    "    - 图像上的猫和狗是分隔开的，但有些任务，后续的输出和之前的内容是相关的。\n",
    "    - 如：“我是中国人，我的母语是__”\n",
    "- RNN引入“记忆”的概念\n",
    "    - 循环2字 来源于其每个元素都执行相同的任务。\n",
    "    - 但是输出依赖于 “输入”和“记忆”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统的MLP/DNN，都是输入和输出相互独立的，。。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a name='rnn2'>1.2 NLP文字序列最爱的RNN</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/rnn6.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x_t$是时间t处的输入\n",
    "- $S_t$是时间t处的“记忆”，$S_t = f(UW_t +WS_{t-1})$，f可以是tanh等\n",
    "- $O_t$是时间t处的输出，比如：是预测下个词的话，可能是softmax输出的属于每个候选词的概率，$O_t = softmax(VS_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**循环神经网络之 结构细节 **\n",
    "- 可以把隐状态$S_t$视作“记忆体”，捕捉了之前时间点上的信息。\n",
    "- 输出$O_t$由当前时间及之前所有的“记忆“共同计算得到。\n",
    "- 很可惜，实际应用中，$S_t$并不能捕捉和保留之前所有信息（记忆有限？）\n",
    "- 不同于CNN，这里的RNN其实整个神经网络都共享一组参数（U,V,W），极大减小了需要训练和预估的参数量。\n",
    "- 图中的$O_t$在有些任务下是不存在的，比如：文本情感分析，其实只需要最后的output结果就行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN与生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/rnn7.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 8000\n",
    "unknown_token = 'UNKNOWN_TOKEN'\n",
    "sentence_start_token = 'SENTENCE_START'\n",
    "sentence_end_token = 'SENTENCE_END'\n",
    "\n",
    "# 读取数据，添加SENTENCE_START和SENTENCENT_END在开头和结尾\n",
    "print('Reading CSV file...')\n",
    "with open('data/reddit-comments-2015-08.csv', 'rb') as f:\n",
    "    reader = csv.reader(f, skipinitialspace=True)\n",
    "    reader.next()\n",
    "    # 分句\n",
    "    sentences = itertools.chain(*[nltk.sent_tokenize(x[0].decode('utf-8').lower()) for x in ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN生成模型模仿语言风格例子：\n",
    "\n",
    "<img src='./images/rnn8.png' width='30%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不同类型的RNN\n",
    "- 双向RNN\n",
    "    - 有些情况下，当前的输出不知依赖于之前的序列元素，还可能依赖之后的序列元素\n",
    "    - 比如： 从一段话中踢掉部分词，让你补全\n",
    "    - 直观理解：双向RNN叠加\n",
    "    <img src='./images/birnn1.png' width='70%'/>\n",
    "\n",
    "- 深层双向RNN\n",
    "    - 和双向RNN的区别是每一步/每个时间点我们设定多层结构\n",
    "    <img src='./images/birnn2.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a name='rnn3'>1.3 BPTT算法</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLP(DNN)与CNN用BP算法求偏导\n",
    "- BPTT和BP是一个思路，只不过既然有step，就和时间t有关系\n",
    "\n",
    "<img src='./images/bptt1.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/bptt2.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/bptt3.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
