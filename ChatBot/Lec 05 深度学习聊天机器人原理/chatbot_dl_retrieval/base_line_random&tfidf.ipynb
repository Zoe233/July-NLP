{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型的基线实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href='#random_guess'>基线模型I：random guesss</a>\n",
    "- <a href='#tf-idf'>基线模型II：TF-IDF</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data \n",
    "train_df = pd.read_csv('./ubuntu_dataset/train.csv')\n",
    "test_df = pd.read_csv('./ubuntu_dataset/test.csv')\n",
    "validataion_df = pd.read_csv('./ubuntu_dataset/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预备predict放置的向量\n",
    "y_test = np.zeros(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think we could import the old comments via r...</td>\n",
       "      <td>basically each xfree86 upload will NOT force u...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not suggesting all - only the ones you mod...</td>\n",
       "      <td>sorry __eou__ i thought it was ubuntu related....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon all __eou__ not entirely related to ...</td>\n",
       "      <td>Yep. __eou__ oh, okay. I wondered what happene...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting __eou__ grub-install worked with /...</td>\n",
       "      <td>thats the one __eou__</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and because Python gives Mark a woody __eou__ ...</td>\n",
       "      <td>(i thought someone was going to make a joke ab...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  i think we could import the old comments via r...   \n",
       "1  I'm not suggesting all - only the ones you mod...   \n",
       "2  afternoon all __eou__ not entirely related to ...   \n",
       "3  interesting __eou__ grub-install worked with /...   \n",
       "4  and because Python gives Mark a woody __eou__ ...   \n",
       "\n",
       "                                           Utterance  Label  \n",
       "0  basically each xfree86 upload will NOT force u...    1.0  \n",
       "1  sorry __eou__ i thought it was ubuntu related....    0.0  \n",
       "2  Yep. __eou__ oh, okay. I wondered what happene...    0.0  \n",
       "3                              thats the one __eou__    1.0  \n",
       "4  (i thought someone was going to make a joke ab...    1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Label\n",
       "count  1000000.000000\n",
       "mean         0.499873\n",
       "std          0.500000\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          1.000000\n",
       "max          1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Ground Truth Utterance</th>\n",
       "      <th>Distractor_0</th>\n",
       "      <th>Distractor_1</th>\n",
       "      <th>Distractor_2</th>\n",
       "      <th>Distractor_3</th>\n",
       "      <th>Distractor_4</th>\n",
       "      <th>Distractor_5</th>\n",
       "      <th>Distractor_6</th>\n",
       "      <th>Distractor_7</th>\n",
       "      <th>Distractor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anyone knows why my stock oneiric exports env ...</td>\n",
       "      <td>nice thanks! __eou__</td>\n",
       "      <td>wrong channel for it, but check efnet.org, uno...</td>\n",
       "      <td>every time the kernel changes, you will lose v...</td>\n",
       "      <td>ok __eou__</td>\n",
       "      <td>!nomodeset &gt; acer __eou__ I'm assuming it is a...</td>\n",
       "      <td>http://www.ubuntu.com/project/about-ubuntu/der...</td>\n",
       "      <td>thx __eou__ unfortunately the program isn't in...</td>\n",
       "      <td>how can I check? By doing a recovery for testi...</td>\n",
       "      <td>my humble apologies __eou__</td>\n",
       "      <td>#ubuntu-offtopic __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i set up my hd such that i have to type a pass...</td>\n",
       "      <td>so you dont know, ok, anyone else? __eou__ you...</td>\n",
       "      <td>nmap is nice, but it wasn't what I was looking...</td>\n",
       "      <td>ok __eou__</td>\n",
       "      <td>cdrom worked fine on windows. __eou__ i dont ...</td>\n",
       "      <td>ah yes, i have read return as rerun __eou__</td>\n",
       "      <td>hm? __eou__</td>\n",
       "      <td>not the case, LTS is every other .04 release. ...</td>\n",
       "      <td>Pretty much __eou__</td>\n",
       "      <td>I used the one I downloaded from AMD __eou__</td>\n",
       "      <td>ffmpeg is part of the package , quixotedon , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im trying to use ubuntu on my macbook pro reti...</td>\n",
       "      <td>just wondering how it runs __eou__</td>\n",
       "      <td>yes, that's what I did, exported it to a \"id_d...</td>\n",
       "      <td>nothing - i am talking about the question of m...</td>\n",
       "      <td>that should fix the fonts being too large __eou__</td>\n",
       "      <td>okay, so hcitool echos back hci0 &lt;mac address ...</td>\n",
       "      <td>I get to the menu with options such as 'try ub...</td>\n",
       "      <td>why do u need analyzer __eou__ it is a toy __e...</td>\n",
       "      <td>Cntrl-C may stop the command but it doesn't fi...</td>\n",
       "      <td>if you're only going to run Ubuntu, just get a...</td>\n",
       "      <td>the ones which are not picked up at the moment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no suggestions? __eou__ links? __eou__ how can...</td>\n",
       "      <td>you cant load anything via usb or cd when luks...</td>\n",
       "      <td>-p  sorry... __eou__  nmap -p22 __eou__ It d...</td>\n",
       "      <td>i guess so i can't even launch it. __eou__</td>\n",
       "      <td>noted __eou__</td>\n",
       "      <td>rxvt-unicode is one __eou__</td>\n",
       "      <td>I tarred all of ~ __eou__</td>\n",
       "      <td>I tarred all of ~ __eou__</td>\n",
       "      <td>I don't really know if I can help, but I was c...</td>\n",
       "      <td>that works just fine, thanks! __eou__</td>\n",
       "      <td>thank you __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just added a second usb printer but not sure...</td>\n",
       "      <td>i was setting it up under the printer configur...</td>\n",
       "      <td>i'd say the most commonly venue would be via L...</td>\n",
       "      <td>the old hardy man page, http://manpages.ubuntu...</td>\n",
       "      <td>i'll give a try __eou__</td>\n",
       "      <td>by the way, the url you posted for davfs is fr...</td>\n",
       "      <td>http://ubuntuforums.org/showthread.php?t=15498...</td>\n",
       "      <td>So I load up putty gui, then what do I do? __e...</td>\n",
       "      <td>you should read error messages, it says 'are ...</td>\n",
       "      <td>waiting the college semester to close just to ...</td>\n",
       "      <td>I was calling myself a jerk. All I know is tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  anyone knows why my stock oneiric exports env ...   \n",
       "1  i set up my hd such that i have to type a pass...   \n",
       "2  im trying to use ubuntu on my macbook pro reti...   \n",
       "3  no suggestions? __eou__ links? __eou__ how can...   \n",
       "4  I just added a second usb printer but not sure...   \n",
       "\n",
       "                              Ground Truth Utterance  \\\n",
       "0                               nice thanks! __eou__   \n",
       "1  so you dont know, ok, anyone else? __eou__ you...   \n",
       "2                 just wondering how it runs __eou__   \n",
       "3  you cant load anything via usb or cd when luks...   \n",
       "4  i was setting it up under the printer configur...   \n",
       "\n",
       "                                        Distractor_0  \\\n",
       "0  wrong channel for it, but check efnet.org, uno...   \n",
       "1  nmap is nice, but it wasn't what I was looking...   \n",
       "2  yes, that's what I did, exported it to a \"id_d...   \n",
       "3    -p  sorry... __eou__  nmap -p22 __eou__ It d...   \n",
       "4  i'd say the most commonly venue would be via L...   \n",
       "\n",
       "                                        Distractor_1  \\\n",
       "0  every time the kernel changes, you will lose v...   \n",
       "1                                         ok __eou__   \n",
       "2  nothing - i am talking about the question of m...   \n",
       "3         i guess so i can't even launch it. __eou__   \n",
       "4  the old hardy man page, http://manpages.ubuntu...   \n",
       "\n",
       "                                        Distractor_2  \\\n",
       "0                                         ok __eou__   \n",
       "1   cdrom worked fine on windows. __eou__ i dont ...   \n",
       "2  that should fix the fonts being too large __eou__   \n",
       "3                                      noted __eou__   \n",
       "4                            i'll give a try __eou__   \n",
       "\n",
       "                                        Distractor_3  \\\n",
       "0  !nomodeset > acer __eou__ I'm assuming it is a...   \n",
       "1        ah yes, i have read return as rerun __eou__   \n",
       "2  okay, so hcitool echos back hci0 <mac address ...   \n",
       "3                        rxvt-unicode is one __eou__   \n",
       "4  by the way, the url you posted for davfs is fr...   \n",
       "\n",
       "                                        Distractor_4  \\\n",
       "0  http://www.ubuntu.com/project/about-ubuntu/der...   \n",
       "1                                        hm? __eou__   \n",
       "2  I get to the menu with options such as 'try ub...   \n",
       "3                          I tarred all of ~ __eou__   \n",
       "4  http://ubuntuforums.org/showthread.php?t=15498...   \n",
       "\n",
       "                                        Distractor_5  \\\n",
       "0  thx __eou__ unfortunately the program isn't in...   \n",
       "1  not the case, LTS is every other .04 release. ...   \n",
       "2  why do u need analyzer __eou__ it is a toy __e...   \n",
       "3                          I tarred all of ~ __eou__   \n",
       "4  So I load up putty gui, then what do I do? __e...   \n",
       "\n",
       "                                        Distractor_6  \\\n",
       "0  how can I check? By doing a recovery for testi...   \n",
       "1                                Pretty much __eou__   \n",
       "2  Cntrl-C may stop the command but it doesn't fi...   \n",
       "3  I don't really know if I can help, but I was c...   \n",
       "4   you should read error messages, it says 'are ...   \n",
       "\n",
       "                                        Distractor_7  \\\n",
       "0                        my humble apologies __eou__   \n",
       "1       I used the one I downloaded from AMD __eou__   \n",
       "2  if you're only going to run Ubuntu, just get a...   \n",
       "3              that works just fine, thanks! __eou__   \n",
       "4  waiting the college semester to close just to ...   \n",
       "\n",
       "                                        Distractor_8  \n",
       "0                           #ubuntu-offtopic __eou__  \n",
       "1  ffmpeg is part of the package , quixotedon , a...  \n",
       "2  the ones which are not picked up at the moment...  \n",
       "3                                  thank you __eou__  \n",
       "4  I was calling myself a jerk. All I know is tha...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Ground Truth Utterance</th>\n",
       "      <th>Distractor_0</th>\n",
       "      <th>Distractor_1</th>\n",
       "      <th>Distractor_2</th>\n",
       "      <th>Distractor_3</th>\n",
       "      <th>Distractor_4</th>\n",
       "      <th>Distractor_5</th>\n",
       "      <th>Distractor_6</th>\n",
       "      <th>Distractor_7</th>\n",
       "      <th>Distractor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "      <td>18920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18920</td>\n",
       "      <td>18026</td>\n",
       "      <td>14066</td>\n",
       "      <td>13998</td>\n",
       "      <td>14162</td>\n",
       "      <td>14116</td>\n",
       "      <td>14200</td>\n",
       "      <td>14149</td>\n",
       "      <td>14064</td>\n",
       "      <td>14068</td>\n",
       "      <td>14202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>best usenet downloader? __eou__ __eot__ there ...</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "      <td>thanks __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>133</td>\n",
       "      <td>142</td>\n",
       "      <td>163</td>\n",
       "      <td>148</td>\n",
       "      <td>130</td>\n",
       "      <td>164</td>\n",
       "      <td>155</td>\n",
       "      <td>151</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Context  \\\n",
       "count                                               18920   \n",
       "unique                                              18920   \n",
       "top     best usenet downloader? __eou__ __eot__ there ...   \n",
       "freq                                                    1   \n",
       "\n",
       "       Ground Truth Utterance    Distractor_0    Distractor_1    Distractor_2  \\\n",
       "count                   18920           18920           18920           18920   \n",
       "unique                  18026           14066           13998           14162   \n",
       "top            thanks __eou__  thanks __eou__  thanks __eou__  thanks __eou__   \n",
       "freq                      152             133             142             163   \n",
       "\n",
       "          Distractor_3    Distractor_4    Distractor_5    Distractor_6  \\\n",
       "count            18920           18920           18920           18920   \n",
       "unique           14116           14200           14149           14064   \n",
       "top     thanks __eou__  thanks __eou__  thanks __eou__  thanks __eou__   \n",
       "freq               148             130             164             155   \n",
       "\n",
       "          Distractor_7    Distractor_8  \n",
       "count            18920           18920  \n",
       "unique           14068           14202  \n",
       "top     thanks __eou__  thanks __eou__  \n",
       "freq               151             156  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='random_guess'>基线模型I：random guesss</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recall(y, y_test, k=1):\n",
    "    '''\n",
    "    手动实现的recall@k的评估方法，评估前k个的召回率。\n",
    "    '''\n",
    "    num_examples = float(len(y))\n",
    "    num_correct = 0\n",
    "    \n",
    "    for predictions,label in zip(y, y_test):\n",
    "        if label in predictions[:k]:\n",
    "            num_correct += 1\n",
    "    return num_correct/num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random(context, utterances):\n",
    "    '''\n",
    "    随机猜答案\n",
    "    '''\n",
    "    return np.random.choice(len(utterances), 10, replace=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.choice(dataset, size, replace=False, p =[])\n",
    "- replace=False无放回\n",
    "- replace=True 有放回，生成的结果可能有重复的\n",
    "- p是指定概率分布，没有指定则是均匀分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 6, 7, 2, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_random(test_df.Context[0], test_df.iloc[0,1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ (1, 10): 0.102537\n",
      "Recall @ (2, 10): 0.204704\n",
      "Recall @ (5, 10): 0.501163\n",
      "Recall @ (10, 10): 1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random predictor\n",
    "y_random = [predict_random(test_df.Context[x], test_df.iloc[x,1:].values) for x in range(len(test_df))]\n",
    "for n in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ ({}, 10): {:g}\".format(n, evaluate_recall(y_random, y_test, n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='tf-idf'>基线模型II：TF-IDF</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFPredictor(object):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    def train(self, data):\n",
    "        '''\n",
    "        给定训练数据用于生成tf-idf词库\n",
    "        '''\n",
    "        # np.append(arr1, arr2) 将两个100w的向量拼接为（200w,)的向量\n",
    "        self.vectorizer.fit(np.append(data.Context.values, data.Utterance.values))\n",
    "    \n",
    "    def predict(self, context, utterances):\n",
    "        # Convert context and utterances into tfidf vector\n",
    "        vector_context = self.vectorizer.transform([context])\n",
    "        vector_doc = self.vectorizer.transform(utterances)\n",
    "        \n",
    "        # The dot product measures the similarity of the resulting vectors\n",
    "        result = np.dot(vector_doc, vector_context.T).todense()\n",
    "        result = np.asarray(result).flatten()\n",
    "        \n",
    "        # Sort by top results and return the indices in descending order\n",
    "        return np.argsort(result, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ (1, 10): 0.485624\n",
      "Recall @ (2, 10): 0.586681\n",
      "Recall @ (5, 10): 0.762474\n",
      "Recall @ (10, 10): 1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate TFIDF predictor\n",
    "pred = TFIDFPredictor()\n",
    "pred.train(train_df)\n",
    "y = [pred.predict(test_df.Context[x], test_df.iloc[x,1:].values) for x in range(len(test_df))]\n",
    "for n in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ ({}, 10): {:g}\".format(n, evaluate_recall(y, y_test, n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************下面是步骤解析********************************\n"
     ]
    }
   ],
   "source": [
    "print('下面是步骤解析'.center(70,'*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 解析步骤\n",
    "Vec = TfidfVectorizer()\n",
    "train_df.Context.values\n",
    "train_df.Utterance.values\n",
    "Vec.fit(np.append(train_df.Context.values,train_df.Utterance.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict解析\n",
    "# 将context问题在tf-idf词库对应的向量化\n",
    "vector_context = Vec.transform([test_df.Context[0]])\n",
    "# 将10个答案在tf-idf词库对应的向量化\n",
    "vector_doc = Vec.transform(test_df.iloc[0,1:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_context.toarray()\n",
    "vector_doc.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过向量点积的方式，计算相似度\n",
    "result = np.dot(vector_doc, vector_context.T).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.04880734],\n",
       "        [0.0348111 ],\n",
       "        [0.02543456],\n",
       "        [0.02057558],\n",
       "        [0.03942579],\n",
       "        [0.00243546],\n",
       "        [0.06546679],\n",
       "        [0.0499886 ],\n",
       "        [0.02529586],\n",
       "        [0.01088604]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04880734, 0.0348111 , 0.02543456, 0.02057558, 0.03942579,\n",
       "       0.00243546, 0.06546679, 0.0499886 , 0.02529586, 0.01088604])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(result).flatten() # 水平拉直为一维的向量 (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[6],\n",
       "        [7],\n",
       "        [0],\n",
       "        [4],\n",
       "        [1],\n",
       "        [2],\n",
       "        [8],\n",
       "        [3],\n",
       "        [9],\n",
       "        [5]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过np.argsort排序\n",
    "np.argsort(result, axis=0)[::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
