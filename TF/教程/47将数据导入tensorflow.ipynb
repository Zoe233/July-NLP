{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将数据导入TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：将数据导入到 TensorFlow 程序的首选方法是使用数据集 API。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外还有三种方法可以将数据导入到 TensorFlow 程序中：\n",
    "\n",
    "- <a href='#feeding'>Feeding</a>：Python的代码在运行每个步骤时提供数据。\n",
    "- <a href='#load_file'>从文件读取</a>：输入管道从 TensorFlow 图的开始处读取文件中的数据。\n",
    "- <a href='#pre_load'>预加载数据</a>：TensorFlow 图中的常量或变量保存所有数据（对于小型数据集）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='feeding'>Feeding</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 的 feed 机制允许您在计算图中向任何张量注入数据。因此， python 计算可以直接将数据导入到图中。\n",
    "\n",
    "通过 feed_dict 参数向启动计算的 run() 或 eval () 调用提供 feed 数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意：“Feeding” 是将数据传送到 TensorFlow 程序的最有效的方式，只能用于小型实验和调试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.Session() as sess:   \n",
    "    input = tf.placeholder(tf.float32)   \n",
    "    classifier = ...   \n",
    "    print(classifier.eval(feed_dict={input: my_python_preprocessing_fn()}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然可以使用 Feed 数据（包括变量和常量）替换任何 Tensor，但最佳做法是使用 tf.placeholder 节点。\n",
    "\n",
    "placeholder（占位符）只是作为 feed 的目标存在。  \n",
    "它未初始化，不包含任何数据如果占位符在没有 Feed 的情况下执行，则会产生错误，因此您不会忘记将其遗忘。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 tensorflow/examples/tutorials/mnist/fully_connected_feed.py 中可以找到在 MNIST 数据上使用占位符和 Feeding 训练的示例, 并在 MNIST 教程中进行了说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([14.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output], feed_dict={input1:[7.], input2:[2.] }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='load_file'>从文件导入</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从文件导入记录的典型管道有以下几个阶段：\n",
    "- 文件名列表\n",
    "- 可选文件名洗牌\n",
    "- 可选时期限制\n",
    "- 文件名队列\n",
    "- 用于文件格式的读取器\n",
    "- 读者用于读取记录的解码器\n",
    "- 可选预处理\n",
    "- 示例队列\n",
    "\n",
    "> 注意：本节讨论使用基于队列的API实现输入管道，该 API 可以被 \\${\\$datasets$Dataset API\\} 完整地替换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件名，shuffling 和 epoch 限制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于文件名列表，请使用常量字符串张量。\n",
    "\n",
    "如：\n",
    "- [\"file0\", \"file1\"]或[(\"file%d\" % i) for i in range(2)]\n",
    "- 或函数：tf.train.match_filenames_once。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将文件名列表传递给 tf.train.string_input_producer 函数。  \n",
    "\n",
    "string_input_producer 创建一个 FIFO 队列，用于保存文件名，直到读取器需要它们为止。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "string_input_producer 有选择的 shuffling 和设置一个最大的 epoch 数。\n",
    "\n",
    "队列运行程序为每个 epoch 将文件名的整个列表添加到队列中一次，如果 shuffling = True，则在一个 epoch 中重新排列文件名。此过程提供了一个统一的文件取样，以便相对于彼此不会对示例进行低估或过度采样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "队列运行程序在与从队列中抽取文件名的读取器分开的线程中工作，因此，shuffling 和  enqueuing 进程不会阻止读取器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择与您的输入文件格式相匹配的读取器，并将文件名队列传递给读取器的读取方法。\n",
    "\n",
    "read 方法输出一个标识文件和记录的密钥 (如果有一些奇怪的记录，则对调试有用) 和一个标量字符串值。使用一个 (或多个) 解码器和转换 ops 将此字符串解码为构成示例的张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CSV文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若要以逗号分隔值 (CSV) 格式读取文本文件, 请使用 tf.TextLineReader 与 tf.decode_csv 操作。\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'col1' [b'col1' b'col2' b'col3']\n",
      "b'1' [b'1' b'1' b'0']\n",
      "b'2' [b'2' b'4' b'0.602059991']\n",
      "b'3' [b'3' b'9' b'0.954242509']\n",
      "b'4' [b'4' b'16' b'1.204119983']\n",
      "b'5' [b'5' b'25' b'1.397940009']\n",
      "b'6' [b'6' b'36' b'1.556302501']\n",
      "b'7' [b'7' b'49' b'1.69019608']\n",
      "b'8' [b'8' b'64' b'1.806179974']\n",
      "b'9' [b'9' b'81' b'1.908485019']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# string_input_producer 创建一个 FIFO 队列，用于保存文件名，直到读取器需要它们为止。\n",
    "filename_queue = tf.train.string_input_producer(['./tf_file.csv'])\n",
    "\n",
    "# 使用 tf.TextLineReader 读取csv文件\n",
    "# 每次一行\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# 指定数据类型：record_defaults里面的数据类型决定了读取的数据类型，而且必须是list形式\n",
    "# 指定默认值：如果读取的值为空，则按record_defaults中对应的值作为 默认值\n",
    "record_defaults = [['1.0'], ['1.0'], ['1.0']]\n",
    "\n",
    "# 解析出的每一个属性都是rank为0的标量\n",
    "col1, col2, col3 = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "# tf.stack是拼接，此处是上下拼接\n",
    "features = tf.stack([col1, col2, col3])\n",
    "\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    # 线程协调器\n",
    "    coord = tf.train.Coordinator()\n",
    "    # 启动线程\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(10):\n",
    "        # 提取一个instance\n",
    "        example, label= sess.run([features, col1])\n",
    "\n",
    "        print(label, example)\n",
    "\n",
    "    #循环结束后，请求关闭所有线程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次读取的执行都从文件中读取一行。   \n",
    "然后，decode_csv 操作将结果解析为张量列表。   \n",
    "该 record_defaults 参数确定生成的张量的类型，并设置在输入字符串中缺少值时要使用的默认值。\n",
    "\n",
    "在调用 run 或 eval 执行读取之前，必须调用 tf.train.start_queue_runners 来填充队列。否则，读取将在等待队列中的文件名时阻止。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 固定长度记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([b'col1', b'col2', b'col3'], dtype=object)]\n",
      "[array([b'1', b'1', b'0'], dtype=object)]\n",
      "[array([b'2', b'4', b'0.602059991'], dtype=object)]\n",
      "[array([b'3', b'9', b'0.954242509'], dtype=object)]\n",
      "[array([b'4', b'16', b'1.204119983'], dtype=object)]\n",
      "[array([b'5', b'25', b'1.397940009'], dtype=object)]\n",
      "[array([b'6', b'36', b'1.556302501'], dtype=object)]\n",
      "[array([b'7', b'49', b'1.69019608'], dtype=object)]\n",
      "[array([b'8', b'64', b'1.806179974'], dtype=object)]\n",
      "[array([b'9', b'81', b'1.908485019'], dtype=object)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'col1' [b'col1' b'col2' b'col3']\n",
      "b'1' [b'1' b'1' b'0']\n",
      "b'2' [b'2' b'4' b'0.602059991']\n",
      "b'3' [b'3' b'9' b'0.954242509']\n",
      "b'4' [b'4' b'16' b'1.204119983']\n",
      "b'5' [b'5' b'25' b'1.397940009']\n",
      "b'6' [b'6' b'36' b'1.556302501']\n",
      "b'7' [b'7' b'49' b'1.69019608']\n",
      "b'8' [b'8' b'64' b'1.806179974']\n",
      "b'9' [b'9' b'81' b'1.908485019']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([1,2,3])\n",
    "b = tf.constant([4,5,6])\n",
    "c = tf.stack([a,b])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
