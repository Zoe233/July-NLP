{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一层版本：仅输入层和输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-1afab7a2097b>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/zoe/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/zoe/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/zoe/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/zoe/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/zoe/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Iter 0,Testing Accuracy 0.8323\n",
      "Iter 1,Testing Accuracy 0.8708\n",
      "Iter 2,Testing Accuracy 0.881\n",
      "Iter 3,Testing Accuracy 0.8882\n",
      "Iter 4,Testing Accuracy 0.8948\n",
      "Iter 5,Testing Accuracy 0.8966\n",
      "Iter 6,Testing Accuracy 0.8995\n",
      "Iter 7,Testing Accuracy 0.901\n",
      "Iter 8,Testing Accuracy 0.9034\n",
      "Iter 9,Testing Accuracy 0.9048\n",
      "Iter 10,Testing Accuracy 0.9062\n",
      "Iter 11,Testing Accuracy 0.9073\n",
      "Iter 12,Testing Accuracy 0.9082\n",
      "Iter 13,Testing Accuracy 0.9098\n",
      "Iter 14,Testing Accuracy 0.9099\n",
      "Iter 15,Testing Accuracy 0.9106\n",
      "Iter 16,Testing Accuracy 0.9115\n",
      "Iter 17,Testing Accuracy 0.913\n",
      "Iter 18,Testing Accuracy 0.9136\n",
      "Iter 19,Testing Accuracy 0.9137\n",
      "Iter 20,Testing Accuracy 0.914\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# 二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化空间：\n",
    "\n",
    "- 神经网络结构\n",
    "    - 隐层的神经元大小\n",
    "    - 隐层数量\n",
    "    - 激活函数\n",
    "    \n",
    "- 二次代价函数：\n",
    "    - MSE\n",
    "    - 交叉熵\n",
    "    \n",
    "- 迭代优化器：梯度下降法，最小二乘法，牛顿法，拟牛顿法\n",
    "     - batch_size\n",
    "     - learning_rate\n",
    "     - epoches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面主要调整了：\n",
    "- 第一次调整：将二次代价函数改为了交叉熵代价函数\n",
    " >二次代价函数\n",
    " >loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "#### 使用交叉熵代价函数\n",
    "> loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "\n",
    "**注意：要使用tf.reduce_mean(）方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较迭代的效果，使用交叉熵的结果收敛更快，效果更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.8249\n",
      "Iter 1,Testing Accuracy 0.8927\n",
      "Iter 2,Testing Accuracy 0.9009\n",
      "Iter 3,Testing Accuracy 0.9053\n",
      "Iter 4,Testing Accuracy 0.9082\n",
      "Iter 5,Testing Accuracy 0.9111\n",
      "Iter 6,Testing Accuracy 0.9116\n",
      "Iter 7,Testing Accuracy 0.9132\n",
      "Iter 8,Testing Accuracy 0.9146\n",
      "Iter 9,Testing Accuracy 0.9171\n",
      "Iter 10,Testing Accuracy 0.9171\n",
      "Iter 11,Testing Accuracy 0.9181\n",
      "Iter 12,Testing Accuracy 0.9187\n",
      "Iter 13,Testing Accuracy 0.9196\n",
      "Iter 14,Testing Accuracy 0.9194\n",
      "Iter 15,Testing Accuracy 0.9203\n",
      "Iter 16,Testing Accuracy 0.9206\n",
      "Iter 17,Testing Accuracy 0.9211\n",
      "Iter 18,Testing Accuracy 0.9219\n",
      "Iter 19,Testing Accuracy 0.9219\n",
      "Iter 20,Testing Accuracy 0.9215\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "\n",
    "# 使用交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改batch_size，将其更改为50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.8711\n",
      "Iter 1,Testing Accuracy 0.8877\n",
      "Iter 2,Testing Accuracy 0.8962\n",
      "Iter 3,Testing Accuracy 0.9015\n",
      "Iter 4,Testing Accuracy 0.9055\n",
      "Iter 5,Testing Accuracy 0.9069\n",
      "Iter 6,Testing Accuracy 0.9089\n",
      "Iter 7,Testing Accuracy 0.9105\n",
      "Iter 8,Testing Accuracy 0.9124\n",
      "Iter 9,Testing Accuracy 0.914\n",
      "Iter 10,Testing Accuracy 0.9138\n",
      "Iter 11,Testing Accuracy 0.9156\n",
      "Iter 12,Testing Accuracy 0.9165\n",
      "Iter 13,Testing Accuracy 0.9175\n",
      "Iter 14,Testing Accuracy 0.9181\n",
      "Iter 15,Testing Accuracy 0.9179\n",
      "Iter 16,Testing Accuracy 0.9186\n",
      "Iter 17,Testing Accuracy 0.9181\n",
      "Iter 18,Testing Accuracy 0.9199\n",
      "Iter 19,Testing Accuracy 0.9202\n",
      "Iter 20,Testing Accuracy 0.92\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 50\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# 二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将batch_size从100改成50，loss函数使用交叉熵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.8798\n",
      "Iter 1,Testing Accuracy 0.9046\n",
      "Iter 2,Testing Accuracy 0.9106\n",
      "Iter 3,Testing Accuracy 0.914\n",
      "Iter 4,Testing Accuracy 0.9155\n",
      "Iter 5,Testing Accuracy 0.9188\n",
      "Iter 6,Testing Accuracy 0.9168\n",
      "Iter 7,Testing Accuracy 0.92\n",
      "Iter 8,Testing Accuracy 0.9204\n",
      "Iter 9,Testing Accuracy 0.9214\n",
      "Iter 10,Testing Accuracy 0.9223\n",
      "Iter 11,Testing Accuracy 0.9227\n",
      "Iter 12,Testing Accuracy 0.9225\n",
      "Iter 13,Testing Accuracy 0.9229\n",
      "Iter 14,Testing Accuracy 0.924\n",
      "Iter 15,Testing Accuracy 0.9239\n",
      "Iter 16,Testing Accuracy 0.925\n",
      "Iter 17,Testing Accuracy 0.9246\n",
      "Iter 18,Testing Accuracy 0.925\n",
      "Iter 19,Testing Accuracy 0.9255\n",
      "Iter 20,Testing Accuracy 0.9247\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 50\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "\n",
    "# 使用交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将batch_size从100改成50，loss函数使用交叉熵，并增加迭代次数，迭代次数从20到200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.8881\n",
      "Iter 50,Testing Accuracy 0.9283\n",
      "Iter 100,Testing Accuracy 0.9301\n",
      "Iter 150,Testing Accuracy 0.929\n",
      "Iter 200,Testing Accuracy 0.9302\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 50\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "\n",
    "# 使用交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(201):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        if epoch % 50 == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将batch_size从100改成50，loss函数使用交叉熵，并增加迭代次数，迭代次数从20到200.\n",
    "+ 调整W和b的参数初始化方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.4339\n",
      "Iter 50,Testing Accuracy 0.913\n",
      "Iter 100,Testing Accuracy 0.9199\n",
      "Iter 150,Testing Accuracy 0.924\n",
      "Iter 200,Testing Accuracy 0.9271\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 50\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W = tf.Variable(tf.truncated_normal([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "\n",
    "# 使用交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(201):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        if epoch % 50 == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将batch_size从100改成50，loss函数使用交叉熵，并增加迭代次数，迭代次数从20到200.\n",
    "+ 调整W和b的参数初始化方式\n",
    "+ 添加一层隐藏层256个神经元，激活函数是tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.5187\n",
      "Iter 50,Testing Accuracy 0.9163\n",
      "Iter 100,Testing Accuracy 0.9223\n",
      "Iter 150,Testing Accuracy 0.9259\n",
      "Iter 200,Testing Accuracy 0.9278\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 50\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.zeros([256]) + 0.1)\n",
    "L1_output = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([256, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L1_output, W2) + b2)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "\n",
    "# 使用交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(201):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        if epoch % 50 == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将batch_size从100改成50，loss函数使用交叉熵，并增加迭代次数，迭代次数从20到200.\n",
    "+ 调整W和b的参数初始化方式\n",
    "+ 添加一层隐藏层256个神经元，激活函数是tanh\n",
    "+ 调整learning_rate为0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.4171\n",
      "Iter 50,Testing Accuracy 0.9053\n",
      "Iter 100,Testing Accuracy 0.911\n",
      "Iter 150,Testing Accuracy 0.9148\n",
      "Iter 200,Testing Accuracy 0.9174\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 50\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.zeros([256]) + 0.1)\n",
    "L1_output = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([256, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L1_output, W2) + b2)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "\n",
    "# 使用交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(201):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        if epoch % 50 == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将batch_size从100改成50，loss函数使用交叉熵，并增加迭代次数，迭代次数从20到200.\n",
    "+ 调整W和b的参数初始化方式\n",
    "+ 添加一层隐藏层256个神经元，激活函数是tanh\n",
    "+ 调整learning_rate为0.1\n",
    "+ 调整优化器为AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.2989\n",
      "Iter 50,Testing Accuracy 0.9121\n",
      "Iter 100,Testing Accuracy 0.9299\n",
      "Iter 150,Testing Accuracy 0.9351\n",
      "Iter 200,Testing Accuracy 0.9392\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 50\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.zeros([256]) + 0.1)\n",
    "L1_output = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([256, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L1_output, W2) + b2)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "\n",
    "# 使用交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(201):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        if epoch % 50 == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将batch_size从100改成50，loss函数使用交叉熵，并增加迭代次数，迭代次数从20到200.\n",
    "+ 调整W和b的参数初始化方式\n",
    "+ 添加一层隐藏层256个神经元，激活函数是tanh\n",
    "+ 调整learning_rate为0.1\n",
    "+ 调整优化器为AdamOptimizer\n",
    "+ 增加迭代次数到2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/zoe/Documents/GitHub/July-NLP/TF/DATAGURU/Lec 03/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.2748\n",
      "Iter 200,Testing Accuracy 0.825\n",
      "Iter 400,Testing Accuracy 0.9457\n",
      "Iter 600,Testing Accuracy 0.9475\n",
      "Iter 800,Testing Accuracy 0.9488\n",
      "Iter 1000,Testing Accuracy 0.9497\n",
      "Iter 1200,Testing Accuracy 0.9509\n",
      "Iter 1400,Testing Accuracy 0.9524\n",
      "Iter 1600,Testing Accuracy 0.9524\n",
      "Iter 1800,Testing Accuracy 0.953\n",
      "Iter 2000,Testing Accuracy 0.952\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(os.path.join(os.getcwd(), 'MNIST_data'), one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 50\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 55000//100=550\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.zeros([256]) + 0.1)\n",
    "L1_output = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([256, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L1_output, W2) + b2)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "\n",
    "# 使用交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "# 正确与否的True or False的列表\n",
    "# tf.argmax返回一维张量中最大的值所在的索引位置\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率\n",
    "# 通过tf.cast(x, dtype)将布尔型转换为浮点型\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(2001):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        if epoch % 200 == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.argmax就是返回最大的那个数值所在的下标。 \n",
    "\n",
    "tf.argmax(array, 1)和tf.argmax(array, 0)有啥区别呢？    \n",
    "    这里面就涉及到一个概念：axis。   \n",
    "    上面例子中的1和0就是axis。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 3 4]\n",
      " [5 4 3]\n",
      " [8 7 2]]\n",
      "[3 3 1]\n",
      "[2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = np.array([[1, 2, 3], [2, 3, 4], [5, 4, 3], [8, 7, 2]])\n",
    "\n",
    "print(test)\n",
    "print(np.argmax(test, 0))\n",
    "print(np.argmax(test, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.cast(x, dtype, name=None)    \n",
    "将x的数据格式转化成dtype.   \n",
    "例如，原来x的数据格式是bool，那么将其转化成float以后，就能够将其转化成0和1的序列。  \n",
    "反之也可以。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([1,0,0,1,1])\n",
    "b = tf.cast(a, dtype=tf.bool)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(b))\n",
    "    #[ True False False  True  True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
