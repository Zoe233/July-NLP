{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a href='http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/'>理解NLP的卷积神经网络</a></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href='#convolutional_filter'>什么是卷积？</a>\n",
    "- <a href='#convolutional_nn'>什么是卷积神经网络？</a>\n",
    "    - <a href='#apply_nlp'>那么，CNN如何适用于NLP？</a>\n",
    "- <a href='#cnn_super_arguments'>CNN超参数</a>\n",
    "- <a href='#cnn_nlp'>卷积神经网络应用于NLP</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们听说卷积神经网络（CNN）时，我们通常会想到计算机视觉。\n",
    "\n",
    "CNN负责图像分类的重大突破，是当今大多数计算机视觉系统的核心，从Facebook的自动照片标签到自动驾驶汽车。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近，我们也开始将CNN应用于自然语言处理中的问题，并获得了一些有趣的结果。在这篇文章中，我将尝试总结：\n",
    "- CNN是什么？\n",
    "- CNN如何在NLP中使用？\n",
    "\n",
    "对于计算机视觉用例来说，CNN背后的直觉有点容易理解，所以我将从那里开始，然后慢慢向NLP迈进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a name='convolutional_filter'>什么是卷积？</a></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理解卷积的最简单方法：\n",
    "- 是将其视为应用于**矩阵**的**滑动窗口函数**。这是一个满口的，但看着可视化变得非常清楚：\n",
    "\n",
    "<img src='./images/Convolution_schematic.gif' width='70%'/>\n",
    "\n",
    "用3×3 Filter抓取特征。    \n",
    "资料来源：http：//deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想象一下，左边的矩阵代表黑白图像。每个条目对应一个像素，0表示黑色，1表示白色（对于灰度图像，通常在0到255之间）。\n",
    "\n",
    "滑动窗口称为  **内核kernel**， **过滤器filter**或**特征检测器feature detector.**。 \n",
    "\n",
    "在这里，我们使用3×3 Filter，将其元素值与原始矩阵相乘，然后将它们相加。  \n",
    "为了获得完整的卷积，我们通过在整个矩阵上滑动 filter 来为每个元素执行此操作。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可能想知道您实际上可以做些什么。这是一些直观的例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter应用1：使用其相邻值对每个像素求平均值会模糊图像：\n",
    "\n",
    "<img src='./images/generic-taj-convmatrix-blur.png' width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter应用2：取像素及其邻居之间的差异来检测边缘：\n",
    "为了直观地理解这一点，请考虑图像中光滑的部分会发生什么，其中像素颜色等于其邻居的颜色：添加取消，结果值为0或黑色。\n",
    "如果强度有锐利边缘，从白色到黑色的过渡，例如，你得到一个很大的差异和产生的白色值\n",
    "\n",
    "<img src='./images/adjacent_side_detector.png' width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在<a href='https://docs.gimp.org/en/plug-in-convmatrix.html'>GIMP手册</a>有一些其他的例子。\n",
    "\n",
    "要了解有关卷积如何工作的更多信息，我还建议查看<a href='http://colah.github.io/posts/2014-07-Understanding-Convolutions/'>Chris Olah关于该主题的帖子。</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a name='convolutional_nn'>什么是卷积神经网络？</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你知道什么是卷积。\n",
    "\n",
    "但CNN呢？\n",
    "\n",
    "CNN基本上只是几层卷积，其中**非线性激活函数**：如ReLU或tanh应用于结果。\n",
    "\n",
    "在传统的前馈神经网络(feedforward neural network)中，我们将每个输入神经元连接到下一层中的每个输出神经元。这也称为**完全连接层(fully connected layer)** 或 **仿射层(affine layer)**。\n",
    "\n",
    "在CNN中我们不这样做。\n",
    "\n",
    "相反，我们在输入层上使用**卷积**来计算输出。这导致局部连接(local connections)，其中输入的每个区域连接到输出中的神经元。 每一层都应用不同的过滤器(filters)，通常是数百或数千，如上所示，并结合其结果。\n",
    "\n",
    "还有一些叫做池(pooling)（子采样(subsampling)）层的东西，但我稍后会介绍。\n",
    "\n",
    "在训练阶段，CNN会 根据您要执行的任务自动学习其过滤器的值。\n",
    "\n",
    "例如，在图像分类中，CNN可以学习从第一层中的原始像素检测边缘，然后使用边缘检测第二层中的简单形状，然后使用这些形状来阻止更高级别的特征，例如：面部形状在较高层。最后一层是使用这些高级功能的分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/cnn01.png' width='90%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个计算有两个方面值得关注：\n",
    "- 位置不变性  Location Invariance    \n",
    "- 组合性  Compositionality  \n",
    "\n",
    "假设您想要对图像中是否有大象进行分类。\n",
    "\n",
    "**位置不变性：**    \n",
    "因为你在整个图像上滑动你的过滤器，你真的不关心那里的大象发生。实际上，**池化(pooling)**还可以为您提供平移translation，旋转rotation和缩放的不变性scaling，但稍后会有更多内容。\n",
    "\n",
    "**组合性：**   \n",
    "第二个关键方面是（本地）组合性。每个过滤器组成将较低级别功能的本地补丁转换为更高级别的表示。\n",
    "\n",
    "这就是CNN在计算机视觉领域如此强大的原因。   \n",
    "直观地说，您可以从像素，边缘形状和形状中更复杂的对象构建边缘。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a name='apply_nlp'>那么，CNN如何适用于NLP？</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代替图像像素，大多数NLP任务的输入是表示为矩阵的句子或文档。\n",
    "\n",
    "矩阵的每一行对应一个标记，通常是一个单词，但它可以是一个字符。也就是说，每行是表示单词的向量。通常，这些向量是word嵌入 （低维表示），如word2vec或GloVe，但它们也可以是将单词索引为词汇表的单热向量。\n",
    "\n",
    "对于使用100维嵌入的10个单词的句子，我们将使用10×100矩阵作为输入。\n",
    "\n",
    "这是我们的“图像”(image)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在视觉中，我们的滤镜会滑过图像的局部色块，但在NLP中，我们通常使用在矩阵的整行上滑动的滤镜（单词）。\n",
    "\n",
    "因此，我们的滤波器的“宽度”通常与输入矩阵的宽度相同。高度或区域大小可以变化，但是通常一次滑动超过2-5个单词的窗口。\n",
    "\n",
    "将上述所有内容放在一起，NLP的卷积神经网络可能看起来像这样（花几分钟时间尝试理解这张图片以及如何计算维度。\n",
    "\n",
    "您现在可以忽略池化，我们稍后会解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a name='cnn_super_arguments'>CNN超参数</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a name='cnn_nlp'>卷积神经网络应用于NLP</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
