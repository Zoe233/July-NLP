{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 引言\n",
    "<p>贝叶斯方法是一个历史悠久，有着坚实的理论基础的方法，同时处理很多问题时直接而又高效，很多高级自然语言处理模型也可以从它演化而来。因此，学习贝叶斯方法，是研究自然语言处理问题的一个非常好的切入口。</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 贝叶斯公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Y|X) = \\frac{P(X|Y)P(Y)}{P(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而贝叶斯公式其实是由以下的联合概率公式推导出来的：\n",
    "$$P(Y,X) = P(Y|X)P(X) = P(X|Y)P(Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，$P(Y)$叫做**先验概率**，$P(Y|X)$叫做**后验概率**，$P(X,Y)$叫做**联合概率**。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 用机器学习的视角理解贝叶斯公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习的视角下，我们把X理解成“具有某特征”，把Y理解成“类别标签”(一般机器学习为题中都是X=>特征, Y=>结果)。\n",
    " \n",
    "在最简单的二分类问题(是与否判定)下，我们将Y理解成“属于某类”的标签。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是贝叶斯公式就变形成了下面的样子:\n",
    "$$P(\"属于某类\"|\"具有某特征\") = \\frac{P(\"属于某特征\"|\"属于某类\")P(\"属于某类\")}{P(\"具有某特征\")}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们简化解释一下上述公式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $P(\"属于某类\"|\"具有某特征\")$ \n",
    "    - 在已知某样本“具有某特征”的条件下，该样本“属于某类”的概率。所以叫做【后验概率】。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $P(\"具有某特征\"|\"属于某类\")$\n",
    "    - 在已知某样本“属于某类”的条件下，该样本“具有某特征”的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $P(\"属于某类\")$\n",
    "    - 在未知某样本具有该“具有某特征”的条件下，该样本“属于某类”的概率。这个叫做【先验概率】。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $P(\"具有某特征\")$\n",
    "    - 在未知某样本“属于某类”的条件下，该样本“具有某特征”的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而我们二分类问题的最终目的就是要\n",
    "    <p style='color:blue'>判断$P(\"属于某类\"|\"具有某特征\")$是否大于$\\frac{1}{2}$就够了。</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯方法把计算“具有某特征的条件下属于某类”的概率转换成需要计算“属于某类的条件下具有某特征”的概率，而后者获取方法就简单多了。  \n",
    "\n",
    "我们只需要找到一些包含已知特征标签的样本，即可进行训练。而样本的类别标签都是明确的，所以贝叶斯方法在机器学习里面属于监督学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 补充：\n",
    "一般【先验概率】【后验概率】是相对出现的，比如$P(Y)$和$P(Y|X)$是关于Y的先验概率和后验概率，$P(X)$和$P(X|Y)$是关于X的先验概率和后验概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 垃圾邮件识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用朴素贝叶斯分类器进行垃圾邮件识别，那目标就是**判断P(\"垃圾邮件\"|\"具有某特征\")是否大于$\\frac{1}{2}$**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在假设我们有垃圾邮件和正常邮件各1万封作为训练集，需要判断新邮件是否为垃圾邮件。\n",
    "\n",
    "新邮件为：“我司可办理正规发票（保真）17%增值税发票点数优惠！”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也就是判断概率 P(“垃圾邮件”|“我司可办理正规发票（保真）17%增值税发票点数优惠！”)\n",
    " 是否大于1/2。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换成的这个概率，计算的方法：就是写个计数器，然后+1 +1 +1统计出所有垃圾邮件和正常邮件中出现这句话的次数啊！！！\n",
    "\n",
    "好，具体点说：\n",
    "$$P(“垃圾邮件”|“我司可办理正规发票（保真）17\\%增值税发票点数优惠！”)\n",
    "   =\\frac{垃圾邮件中出现这句话的次数}{垃圾邮件中出现这句话的次数+正常邮件中出现这句话的次数}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个很悲哀但是很现实的结论： **训练集是有限的，而句子的可能性则是无限的。所以覆盖所有句子可能性的训练集是不存在的。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以解决方法是？ **句子的可能性无限，但是词语就那么些！！**汉语常用字2500个，常用词语也就56000个(你终于明白小学语文老师的用心良苦了)。按人们的经验理解，两句话意思相近并不强求非得每个字、词语都一样。比如“我司可办理正规发票，17%增值税发票点数优惠！”，这句话就比之前那句话少了“（保真）”这个词，但是意思基本一样。如果把这些情况也考虑进来，那样本数量就会增加，这就方便我们计算了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是，我们可以**不拿句子作为特征**，而是拿句子里面的**词语（组合）作为特征**去考虑。比如**“正规发票”**可以作为一个单独的词语，**“增值税”**也可以作为一个单独的词语等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 句子“我司可办理正规发票，17%增值税发票点数优惠！”就可以变成（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是你接触到了中文NLP中，最最最重要的技术之一：分词！！！也就是把一整句话拆分成更**细粒度的词语**来进行表示。 \n",
    "\n",
    "另外，分词之后去除标点符号、数字甚至无关成分(停用词)是特征预处理中的一项技术。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中文分词是一个专门的技术领域，python有一个非常方便的分词工具jieba，假定我们已经完成分词工作："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们观察（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)，这可以理解成一个向量：向量的每一维度都表示着该特征词在文本中的特定位置存在。这种将特征拆分成更小的单元，依据这些更灵活、更细粒度的特征进行判断的思维方式，在自然语言处理与机器学习中都是非常常见又有效的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此贝叶斯公式就变成了："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><p>$P(“垃圾邮件”|（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）$\n",
    "$=\\frac{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|\"垃圾邮件\"）P(“垃圾邮件”)}{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)) }$</p>\n",
    "<p>$P(“正常邮件”|（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)）$\n",
    "$=\\frac{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|\"正常邮件\"）P(“正常邮件”)}{P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)) }$</p>\n",
    "</blockquote>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 条件独立假设"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们马上会看到一个非常简单粗暴的假设。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率 P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|\"垃圾邮件\"）\n",
    "\n",
    "依旧不够好求，我们引进一个很朴素的近似。为了让公式显得更加紧凑，我们令字母S表示“垃圾邮件”,令字母H表示“正常邮件”。近似公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><p>$P(（“我”,“司”,“可”,“办理”,“正规发票”,“保真”,“增值税”,“发票”,“点数”,“优惠”)|S）$<br>\n",
    "$=P(“我”|S）×P(“司”|S）×P(“可”|S）×P(“办理”|S）×P(“正规发票”|S）$\n",
    "$×P(“保真”|S）×P(“增值税”|S）×P(“发票”|S）×P(“点数”|S）×P(“优惠”|S)$</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这就是传说中的**条件独立假设**。\n",
    "\n",
    "基于“正常邮件”的条件独立假设的式子与上式类似，此处省去。接着，将条件独立假设代入上面两个相反事件的贝叶斯公式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是我们就只需要比较以下两个式子的大小："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><p>$C = P(“我”|S)P(“司”|S)P(“可”|S)P(“办理”|S)P(“正规发票”|S)$\n",
    "$×P(“保真”|S)P(“增值税”|S)P(“发票”|S)P(“点数”|S)P(“优惠”|S)P(“垃圾邮件”)$\n",
    "$\\overline{C}=P(“我”|H)P(“司”|H)P(“可”|H)P(“办理”|H)P(“正规发票”|H)$\n",
    "$×P(“保真”|H)P(“增值税”|H)P(“发票”|H)P(“点数”|H)P(“优惠”|H)P(“正常邮件”) $</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过**条件独立假设**处理后，式子中的每一项都特别好求，只需要**分别统计各类邮件中该关键词出现的概率**即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><p>$P(“发票”|S）=\\frac{垃圾邮件中所有“发票”的次数}{垃圾邮件中所有词语的次数}$</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计次数非常方便，而且样本数量足够大，算出来的概率比较接近真实。于是垃圾邮件识别的问题就可解了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
