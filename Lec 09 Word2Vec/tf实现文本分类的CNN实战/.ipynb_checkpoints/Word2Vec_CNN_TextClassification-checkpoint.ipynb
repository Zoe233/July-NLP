{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec+CNN做文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "论文详见《Convolutional Neural Networks for Sentence Classification》\n",
    "http://arxiv.org/abs/1408.5882\n",
    "\n",
    "Theano完成的代码版本：\n",
    "https://github.com/yoonkim/CNN_sentence\n",
    "\n",
    "TensorFlow改写的代码版本：\n",
    "https://github.com/dennybritz/cnn-text-classification-tf\n",
    "\n",
    "添加分词和中文词向量映射之后，可用于中文文本分类(情感分析)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 本节内容主要记录TensorFlow的版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow版本介绍：\n",
    "本节的代码实现主要基于“<a href='http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/'>在TensorFlow中实现CNN进行文本分类</a>”的论文。\n",
    "\n",
    "具体的思想和内容，参见论文，此处会酌情提取相关内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将实现一个类似于Kim Yoon的<a href='https://arxiv.org/abs/1408.5882'>用于句子分类</a>的<a href='https://arxiv.org/abs/1408.5882'>卷积神经网络</a>的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文提出的模型在一系列文本分类任务（如情感分析）中实现了良好的分类性能，并已成为新文本分类体系结构的标准基线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我假设您已经熟悉应用于NLP的卷积神经网络的基础知识。如果没有，我建议首先阅读了解<a href='http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/'>NLP的卷积神经网络</a>，以获得必要的背景知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: 数据和预处理 Data and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将在这篇文章中使用的数据集是来自<a href='http://www.cs.cornell.edu/people/pabo/movie-review-data/'>烂番茄的电影评论数据</a>- 原始论文中也使用的数据集之一。\n",
    "\n",
    "数据集包含10,662个示例评论句子，半正面和半负面。数据集的大小约为20k。请注意，由于此数据集非常小，我们可能会过度使用强大的模型。此外，数据集没有官方训练集/测试集拆分，因此我们只使用10％的数据作为开发集dev set。原始论文显示了对数据进行10倍交叉验证(10-fold cross-validation)的结果。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我不会在这篇文章中讨论数据预处理代码，但它可以在Github上获得并执行以下操作：\n",
    "\n",
    "1. 从原始数据文件中加载正面和负面的句子。\n",
    "2. 使用与原始论文<a href='https://github.com/yoonkim/CNN_sentence'>Github: 相同的代码</a>清理文本数据。\n",
    "3. 将每个句子填充到最大句子长度59。我们将特殊<PAD\\>标记附加到所有其他句子，使它们成为59个单词的句子。将句子填充到相同长度是有用的，因为它允许我们有效地批量处理我们的数据，因为批处理中的每个示例必须具有相同的长度。\n",
    "4. 构建词汇索引并将每个单词映射到0到18,765之间的整数（词汇量大小）。每个句子都成为整数向量Each sentence becomes a vector of integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: 模型 The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
