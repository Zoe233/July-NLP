{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文情感分析\n",
    "Chinese sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib  # 可以把数据用二进制形式存储，读取\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据，做预处理（分词），切分训练集和测试集\n",
    "下面内容均为分步解析，函数load_file_and_preprocessing才是主体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>做为一本声名在外的流行书，说的还是广州的外企，按道理应该和我的生存环境差不多啊。但是一看之下...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>作者有明显的自恋倾向，只有有老公养不上班的太太们才能像她那样生活。很多方法都不实用，还有抄袭...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>作者完全是以一个过来的自认为是成功者的角度去写这个问题，感觉很不客观。虽然不是很喜欢，但是，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>作者提倡内调，不信任化妆品，这点赞同。但是所列举的方法太麻烦，配料也不好找。不是太实用。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>作者的文笔一般，观点也是和市面上的同类书大同小异，不推荐读者购买。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  做为一本声名在外的流行书，说的还是广州的外企，按道理应该和我的生存环境差不多啊。但是一看之下...\n",
       "1  作者有明显的自恋倾向，只有有老公养不上班的太太们才能像她那样生活。很多方法都不实用，还有抄袭...\n",
       "2  作者完全是以一个过来的自认为是成功者的角度去写这个问题，感觉很不客观。虽然不是很喜欢，但是，...\n",
       "3       作者提倡内调，不信任化妆品，这点赞同。但是所列举的方法太麻烦，配料也不好找。不是太实用。\n",
       "4                  作者的文笔一般，观点也是和市面上的同类书大同小异，不推荐读者购买。"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = pd.read_excel('data/neg.xls', header=None, index=None)\n",
    "pos = pd.read_excel('data/pos.xls', header=None, index=None)\n",
    "\n",
    "neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...\n",
       "1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
       "2  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
       "3  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
       "4  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10428, 1)\n",
      "(10677, 1)\n"
     ]
    }
   ],
   "source": [
    "print(neg.shape)\n",
    "print(pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'做 父母 一定 要 有 刘墉 这样 的 心态 ， 不断 地 学习 ， 不断 地 进步 ， 不断 地 给 自己 补充 新鲜血液 ， 让 自己 保持 一颗 年轻 的 心 。 我 想 ， 这 是 他 能 很 好 的 和 孩子 沟通 的 一个 重要 因素 。 读 刘墉 的 文章 ， 总能 让 我 看到 一个 快乐 的 平易近人 的 父亲 ， 他 始终 站 在 和 孩子 同样 的 高度 ， 给 孩子 创造 着 一个 充满 爱 和 自由 的 生活 环境 。 很 喜欢 刘墉 在 字里行间 流露出 的 做 父母 的 那种 小 狡黠 ， 让 人 总是 忍俊不禁 ， 父母 和 子女 之间 有时候 也 是 一种 战斗 ， 武力 争斗 过于 低级 了 ， 智力 较量 才 更 有 趣味 。 所以 ， 做 父母 的 得 加把劲 了 ， 老 思想 老 观念 注定 会 一败涂地 ， 生命不息 ， 学习 不止 。 家庭教育 ， 真的 是 乐在其中 。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(list(jieba.cut(pos[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.concatenate((np.ones(len(pos)), np.zeros(len(neg))))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上内容均为分步解析，函数load_file_and_preprocessing才是主体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_and_preprocessing():\n",
    "    # 读取neg, pos内容\n",
    "    neg = pd.read_excel('data/neg.xls', header=None, index=None)\n",
    "    pos = pd.read_excel('data/pos.xls', header=None, index=None)\n",
    "    \n",
    "    # 分词\n",
    "    cw = lambda x: list(jieba.cut(x))\n",
    "    pos['words'] = pos[0].apply(cw)\n",
    "    neg['words'] = neg[0].apply(cw)\n",
    "    \n",
    "    # 生成对应的pos:1 , neg: 0 的label\n",
    "    y = np.concatenate((np.ones(len(pos)), np.zeros(len(neg))))\n",
    "    new_df = np.concatenate((pos['words'], neg['words']))\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(new_df, y, test_size=0.2)\n",
    "    \n",
    "    np.save('svm_data/y_train.npy', y_train)\n",
    "    np.save('svm_data/y_test.npy', y_test)\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = load_file_and_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train's shape:  (16884,)\n",
      "x_test's shape:  (4221,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train\\'s shape: ', x_train.shape)\n",
    "print('x_test\\'s shape: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. ... 0. 0. 1.]\n",
      "(16884,)\n"
     ]
    }
   ],
   "source": [
    "print(np.load('svm_data/y_train.npy'))\n",
    "print(np.load('svm_data/y_train.npy').shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对每个句子的所有词向量取均值，来生成一个句子的vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sentence_vector(text, size, imdb_w2v):\n",
    "    vec = np.zeros(size).reshape((1,size))\n",
    "    count = 0\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += imdb_w2v.wv[word].reshape((1, size))\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3642161, 5392895)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据x_train的文本信息，训练word2vec的模型\n",
    "imdb_w2v = Word2Vec(size=300, min_count=10)\n",
    "imdb_w2v.build_vocab(x_train)\n",
    "imdb_w2v.train(x_train, total_examples=imdb_w2v.corpus_count, epochs=imdb_w2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'技术 区里 唯一 的 四星级 酒店 , 外观 不起眼 , 但 服务 感觉 很 不错 , 尤其 ?'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_w2v.wv['技术'].reshape((1,300)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_sentence_vector(x_train[0], 300, imdb_w2v).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_vecs(x_train, x_test):\n",
    "    n_dim = 300\n",
    "    \n",
    "    # 初始化模型和词表\n",
    "    imdb_w2v = Word2Vec(size=n_dim, min_count=10)\n",
    "    imdb_w2v.build_vocab(x_train)\n",
    "    \n",
    "    # 在评论训练集上建模\n",
    "    imdb_w2v.train(x_train, total_examples=imdb_w2v.corpus_count, epochs=imdb_w2v.epochs)\n",
    "    \n",
    "    train_vecs = np.concatenate([build_sentence_vector(z, n_dim, imdb_w2v) for z in x_train])\n",
    "    \n",
    "    np.save('svm_data/train_vecs.npy', train_vecs)\n",
    "    \n",
    "    print(train_vecs.shape)\n",
    "    \n",
    "    # 在测试集上训练\n",
    "    imdb_w2v.train(x_test, total_examples=imdb_w2v.corpus_count, epochs=imdb_w2v.epochs)\n",
    "    imdb_w2v.save('svm_data/w2v_model/w2v_model.pkl')\n",
    "    \n",
    "    # Build test tweet vectors then scale\n",
    "    test_vecs = np.concatenate([build_sentence_vector(z, n_dim, imdb_w2v) for z in x_test])\n",
    "    \n",
    "    np.save('svm_data/test_vecs.npy', test_vecs)\n",
    "    \n",
    "    print(test_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16884, 300)\n",
      "(4221, 300)\n"
     ]
    }
   ],
   "source": [
    "get_train_vecs(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train_vecs = np.load('svm_data/train_vecs.npy')\n",
    "    y_train = np.load('svm_data/y_train.npy')\n",
    "    test_vecs = np.load('svm_data/test_vecs.npy')\n",
    "    y_test = np.load('svm_data/y_test.npy')\n",
    "    return train_vecs, y_train, test_vecs, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs, y_train, test_vecs, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vecs shape:  (16884, 300)\n",
      "test_vecs shape:  (4221, 300)\n",
      "y_train shape:  (16884,)\n",
      "y_test shape:  (4221,)\n"
     ]
    }
   ],
   "source": [
    "print('train_vecs shape: ', train_vecs.shape)\n",
    "print('test_vecs shape: ', test_vecs.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练SVM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train(train_vecs, y_train, test_vecs, y_test):\n",
    "    clf = SVC(kernel='rbf', verbose=True)\n",
    "    clf.fit(train_vecs, y_train)\n",
    "    joblib.dump(clf, 'svm_data/svm_model/model.pkl')\n",
    "    print(clf.score(test_vecs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.7825159914712153\n"
     ]
    }
   ],
   "source": [
    "svm_train(train_vecs, y_train, test_vecs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建待预测句子的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_vecs(words):\n",
    "    n_dim = 300\n",
    "    imdb_w2v = Word2Vec.load('svm_data/w2v_model/w2v_model.pkl')\n",
    "    train_vecs = build_sentence_vector(words, n_dim, imdb_w2v)\n",
    "    \n",
    "    return train_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.34407905e-01,  1.44382074e-01,  1.88170485e-01,\n",
       "        -4.21376348e-01, -6.39175661e-01,  2.31335017e-01,\n",
       "        -7.87728578e-02, -5.26599847e-01, -5.63985065e-01,\n",
       "        -1.90347357e-01,  2.71049142e-03, -3.21473327e-01,\n",
       "        -5.21203991e-01, -2.74984868e-01,  4.34153784e-01,\n",
       "        -3.01018286e-01,  1.47170902e-01,  2.03365717e-01,\n",
       "        -8.27119797e-01, -1.98496759e-01,  7.15714865e-02,\n",
       "        -9.73958895e-02,  4.59843230e-01, -2.05852618e-01,\n",
       "        -2.52373662e-01, -3.71734537e-02,  1.56005062e-02,\n",
       "        -2.32473850e-01,  9.26987249e-02, -2.94366710e-01,\n",
       "        -1.99573599e-01,  3.41328844e-01,  5.03863804e-02,\n",
       "         8.55444919e-02, -2.77665779e-01,  3.52835642e-01,\n",
       "         9.58216488e-02, -3.48808561e-01,  1.91210520e-01,\n",
       "        -3.92713197e-01, -3.90093991e-01,  5.72854578e-02,\n",
       "        -1.17767282e-01,  1.71530101e-01, -6.02068968e-01,\n",
       "        -3.68573114e-01, -1.26361307e-01,  1.14220306e-02,\n",
       "        -6.66302567e-01,  2.70749770e-01, -3.52008369e-01,\n",
       "         3.06200445e-01,  4.61307742e-01,  3.55952378e-01,\n",
       "        -2.09649117e-01,  3.33398325e-01, -3.67005508e-01,\n",
       "        -4.06116106e-01,  4.59333599e-01,  2.82539311e-01,\n",
       "        -4.82653635e-01, -1.88370852e-01, -1.07737612e-01,\n",
       "         4.40300010e-01,  6.79878153e-01, -7.60456473e-02,\n",
       "        -5.99219967e-02,  1.28106497e-01, -3.80545540e-01,\n",
       "        -1.89519737e-01, -5.26632935e-01,  4.72398400e-01,\n",
       "         3.81966567e-01,  1.67147540e-01,  2.85876449e-01,\n",
       "        -2.43565068e-03, -4.96351525e-01,  3.61737457e-01,\n",
       "         2.08114646e-03, -7.29041081e-03,  2.38891445e-01,\n",
       "         2.08310362e-01,  7.33845063e-01, -1.59247106e-01,\n",
       "        -3.03699059e-01,  6.18702454e-01,  3.10252004e-01,\n",
       "         1.51572795e-01,  2.44489461e-01,  5.79596758e-02,\n",
       "         8.59969109e-02,  3.97244968e-01,  1.09888237e-01,\n",
       "        -2.76198141e-01, -1.82333387e-01,  6.99782893e-02,\n",
       "         5.94457731e-01, -4.69937928e-01,  4.15244628e-01,\n",
       "        -3.20627246e-01, -5.69374640e-01,  2.25417343e-01,\n",
       "         5.15160493e-01,  4.93854105e-01, -1.69574365e-01,\n",
       "        -5.86455718e-01, -8.63939349e-02, -4.26457934e-02,\n",
       "        -5.30821919e-01,  4.40062104e-01, -2.45544552e-02,\n",
       "         2.42299598e-01, -4.99696426e-01, -6.17947612e-01,\n",
       "        -1.62646581e-01, -3.13810452e-01, -8.66045840e-02,\n",
       "         4.35382828e-01, -2.43162059e-01,  1.38769660e-01,\n",
       "         2.67522417e-01,  1.08519129e-01,  6.98088452e-01,\n",
       "         2.55051063e-01, -6.44591518e-01,  8.08520484e-01,\n",
       "         2.68880669e-01, -2.60582190e-01, -3.72883949e-01,\n",
       "        -3.17906015e-01, -3.16064901e-01, -2.65558905e-01,\n",
       "        -2.76214818e-01, -5.82540995e-02, -2.63448298e-01,\n",
       "         6.27014688e-01,  2.54176418e-01, -4.80313312e-01,\n",
       "        -1.67469434e-01, -6.15306772e-01, -1.55134954e-01,\n",
       "         5.93223099e-01,  2.75157046e-01,  1.06226588e-01,\n",
       "        -4.90969159e-02,  4.05066438e-01, -1.39704229e-01,\n",
       "        -8.10188875e-02,  3.69746022e-01,  4.94834147e-02,\n",
       "         1.38729863e-01, -8.23584914e-01,  2.06063945e-01,\n",
       "        -2.03377306e-02, -3.26773688e-01,  6.74084987e-01,\n",
       "         3.45900221e-01, -1.57502392e-01,  6.11050759e-01,\n",
       "        -1.22938968e-01,  3.19253936e-01,  1.75656389e-01,\n",
       "        -1.08298021e-01, -7.60960490e-01, -5.71394963e-02,\n",
       "        -4.21256404e-01, -6.43000051e-01,  4.36303295e-01,\n",
       "         2.18598645e-01, -1.26963499e+00,  7.47260030e-01,\n",
       "        -1.61071256e-01,  1.42400143e-01, -1.00476243e-01,\n",
       "         2.51054496e-01, -5.65422937e-01,  1.11799985e-01,\n",
       "         5.62685728e-01,  1.35100505e-01, -5.18515071e-01,\n",
       "        -2.65773978e-01, -3.62067168e-01, -2.22294364e-01,\n",
       "         7.66012695e-01,  1.91797353e-02,  2.21705116e-01,\n",
       "        -6.87224306e-01,  3.14282797e-01, -2.47344900e-01,\n",
       "         1.76290985e-01, -3.66662227e-01, -8.74259919e-02,\n",
       "         3.95228989e-01,  3.16132225e-01,  2.17911664e-01,\n",
       "         4.89642243e-01, -1.78231451e-01,  7.42278256e-01,\n",
       "         5.57273440e-01,  6.44429941e-01, -9.46955387e-01,\n",
       "        -2.40157973e-01, -6.43930797e-01,  2.41336371e-01,\n",
       "        -2.72237882e-01,  2.86404327e-01,  2.30711035e-01,\n",
       "        -3.23723339e-01,  1.44354459e-02, -4.52259272e-01,\n",
       "        -4.01721972e-01,  3.08193028e-01, -3.99885634e-02,\n",
       "         9.93975922e-02,  4.18820984e-02, -1.34180370e-01,\n",
       "         1.77141274e-02, -9.51464362e-02,  5.42798147e-01,\n",
       "         8.54647947e-02, -4.37759878e-01, -6.63241312e-01,\n",
       "         6.68755457e-01, -1.47522517e-01,  1.08808942e-01,\n",
       "        -1.84573451e-01,  1.08183887e-01,  1.59259032e-01,\n",
       "        -2.63042413e-01,  1.88693032e-01,  3.88402320e-01,\n",
       "        -2.17622645e-01, -6.88093938e-02, -5.86857405e-01,\n",
       "         1.53723550e-02, -2.85726245e-01,  3.61720342e-01,\n",
       "         4.07045689e-01,  7.43708946e-02, -1.33561254e-01,\n",
       "         3.81470747e-01, -3.82889668e-02,  1.85017686e-01,\n",
       "        -4.27137904e-01, -2.15218820e-01, -5.18225199e-01,\n",
       "         3.84967044e-01, -6.20133472e-01, -2.87580847e-01,\n",
       "        -4.66397619e-02, -1.85317533e-01, -2.59469116e-01,\n",
       "        -7.71601349e-02,  4.19129055e-01, -5.90952132e-02,\n",
       "         3.27497594e-01, -1.02624381e-01,  6.65329264e-01,\n",
       "        -1.09513849e-03, -5.27135362e-01,  3.52752104e-01,\n",
       "        -6.25164621e-01,  4.10890877e-01, -2.87917625e-01,\n",
       "         5.78762125e-02, -6.46703616e-01, -1.67367145e-01,\n",
       "         8.60730491e-02,  3.87483180e-01, -3.87494516e-01,\n",
       "        -7.65769240e-02,  2.94741131e-02,  3.57630900e-01,\n",
       "        -2.03580506e-01,  2.88853489e-01,  3.17027889e-01,\n",
       "         1.26513518e-01,  4.46227752e-01,  5.90018749e-01,\n",
       "         2.90154878e-01,  1.12872712e-01,  1.02505766e-01,\n",
       "         3.06467467e-01, -1.88016608e-01,  4.77384020e-01,\n",
       "         4.00924891e-01, -2.15667754e-01, -1.78473210e-01,\n",
       "         5.24758711e-01,  3.18096081e-01, -5.58880098e-01,\n",
       "        -7.32397614e-02,  6.48447819e-01, -6.31291829e-01,\n",
       "         8.39072838e-02, -4.72224750e-01, -2.54692301e-01,\n",
       "         1.10925245e+00,  5.06378449e-01,  5.40003544e-02]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predict_vecs(list(jieba.cut('我们是中国人')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对单个句子进行情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict(string):\n",
    "    words = jieba.lcut(string)\n",
    "    words_vecs = get_predict_vecs(words)\n",
    "    clf = joblib.load('svm_data/svm_model/model.pkl')\n",
    "    \n",
    "    result = clf.predict(words_vecs)\n",
    "    \n",
    "    if int(result[0]) == 1:\n",
    "        print(string, 'postive')\n",
    "    else:\n",
    "        print(string, 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电池充完了电连手机都打不开.简直烂的要命.真是金玉其外,败絮其中!连5号电池都不如 negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "string = '电池充完了电连手机都打不开.简直烂的要命.真是金玉其外,败絮其中!连5号电池都不如'\n",
    "svm_predict(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
